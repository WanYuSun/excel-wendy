"""
union-sheets.py

ä¸€ä¸ªç”¨äºè¯»å–Excelæ–‡ä»¶ä¸­å¤šä¸ªsheetså¹¶ä½¿ç”¨DuckDBè¿›è¡ŒUNIONæ“ä½œçš„é€šç”¨å·¥å…·ã€‚

æ ¸å¿ƒåŠŸèƒ½:
- ä½¿ç”¨openpyxlè¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheetåç§°
- ä½¿ç”¨DuckDBçš„read_xlsxå‡½æ•°ä¾æ¬¡è¯»å–æ¯ä¸ªsheet
- æä¾›ä¸¤ä¸ªæ ¸å¿ƒå‡½æ•°ï¼šunion_sheets å’Œ unique_keys

ğŸ”§ å‡½æ•°1: union_sheets
å‚æ•°:
- excel_file: Excelæ–‡ä»¶è·¯å¾„
- table_name: è¾“å‡ºè¡¨å  
- conn: DuckDBè¿æ¥å¯¹è±¡

åŠŸèƒ½:
- è¯»å–Excelæ‰€æœ‰sheetså¹¶UNION ALLåˆå¹¶
- ä¿ç•™æ‰€æœ‰åŸå§‹æ•°æ®ï¼Œä¸å»é‡

ğŸ”§ å‡½æ•°2: unique_keys  
å‚æ•°:
- conn: DuckDBè¿æ¥å¯¹è±¡
- table_name: è¾“å…¥è¡¨å
- projections: æŠ•å½±åˆ—è¡¨ [(è¡¨è¾¾å¼, åˆ«å), ...]

åŠŸèƒ½:
- ä½¿ç”¨GROUP BY ALLè‡ªåŠ¨å»é‡
- æ”¯æŒçµæ´»çš„åˆ—æŠ•å½±å’Œé‡å‘½å
- è¿”å›æ–°è¡¨å: u_{table_name}

ğŸ’¡ ä½¿ç”¨æµç¨‹:
1. union_sheets() - åˆå¹¶æ‰€æœ‰sheets
2. unique_keys() - æŒ‰éœ€å»é‡å’ŒæŠ•å½±

è®¾è®¡åŸåˆ™:
- æ¯ä¸ªå‡½æ•°èŒè´£å•ä¸€æ˜ç¡®
- å¯ä»¥ç‹¬ç«‹ä½¿ç”¨æˆ–ç»„åˆä½¿ç”¨
- ä¿æŒAPIç®€æ´æ¸…æ™°
- è®°å½•æ¯ä¸ªSQLæ“ä½œçš„æ‰§è¡Œæ—¶é—´

Bootstrapæµç¨‹ (é¦–æ¬¡ä½¿ç”¨):
1. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ:
   python3 -m venv venv

2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–:
   source venv/bin/activate
   pip3 install -i https://bytedpypi.byted.org/simple openpyxl duckdb

3. è¿è¡Œè„šæœ¬:
   python3 test/union-sheets.py <excel_file_path>

4. æŸ¥çœ‹ç»“æœ:
   # æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®åº“æ–‡ä»¶
   ls -la excel.db
   
   # æŸ¥çœ‹testè¡¨å†…å®¹ (å¯é€‰)
   python3 -c "
   import duckdb
   conn = duckdb.connect('excel.db')
   result = conn.execute('SELECT * FROM test ORDER BY 1').fetchall()
   for row in result: print(row)
   conn.close()
   "

åç»­ä½¿ç”¨ (ç¯å¢ƒå·²é…ç½®):
   source venv/bin/activate && python3 test/union-sheets.py <excel_file_path>

ä½¿ç”¨è¯´æ˜:
1. ç¡®ä¿è¾“å…¥çš„Excelæ–‡ä»¶å­˜åœ¨ä¸”åŒ…å«å¤šä¸ªsheet
2. æ‰€æœ‰sheetåº”å…·æœ‰ç›¸åŒçš„åˆ—ç»“æ„å’Œæ•°æ®ç±»å‹
3. ç¨‹åºä¼šæŒ‰ç¬¬ä¸€åˆ—å»é‡ï¼Œå¦‚æœå¤šä¸ªsheetä¸­æœ‰ç›¸åŒçš„ç¬¬ä¸€åˆ—å€¼ï¼Œä¿ç•™æœ€åå¤„ç†çš„sheetä¸­çš„è®°å½•
4. ç¨‹åºä¼šè‡ªåŠ¨è·³è¿‡ç©ºçš„sheet
5. ç»“æœä¿å­˜åœ¨å½“å‰ç›®å½•çš„excel.dbæ–‡ä»¶ä¸­çš„testè¡¨

å»é‡é€»è¾‘:
- ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºå»é‡çš„é”®å€¼
- å½“å¤šä¸ªsheetä¸­å­˜åœ¨ç›¸åŒçš„ç¬¬ä¸€åˆ—å€¼æ—¶ï¼Œä¿ç•™åé¢sheetä¸­çš„è®°å½•
- ä¾‹å¦‚ï¼šSheet1ä¸­æœ‰è®°å½•Aï¼ŒSheet2ä¸­ä¹Ÿæœ‰è®°å½•Aï¼Œæœ€ç»ˆä¿ç•™Sheet2ä¸­çš„è®°å½•A

è¾“å‡ºè¯´æ˜:
- ç¨‹åºä¼šæ˜¾ç¤ºå‘ç°çš„sheetæ•°é‡å’Œåç§°
- æ˜¾ç¤ºå»é‡å‰åçš„è¡Œæ•°å¯¹æ¯”
- æ˜¾ç¤ºæœ€ç»ˆè¡¨çš„ç»“æ„ä¿¡æ¯
- è®°å½•æ¯ä¸ªSQLæ“ä½œçš„æ‰§è¡Œæ—¶é—´
- ç”Ÿæˆexcel.dbæ•°æ®åº“æ–‡ä»¶ï¼ŒåŒ…å«testè¡¨

ä¾èµ–:
- Python 3.7+
- openpyxl (Excelæ–‡ä»¶è¯»å–)
- duckdb (æ•°æ®å¤„ç†å’ŒSQLæ“ä½œ)

ç”¨æ³•:
    python union-sheets.py <excel_file_path> [é€‰é¡¹]

åŸºæœ¬ç¤ºä¾‹:
    # é»˜è®¤ç”¨æ³•ï¼ˆæŒ‰ç¬¬ä¸€åˆ—è‡ªåŠ¨å»é‡ï¼‰
    python union-sheets.py /Users/bytedance/Documents/excel/Book1.xlsx
    
    # ä½¿ç”¨UNIONæŠ•å½±ä¼˜åŒ–æ€§èƒ½
    python union-sheets.py data.xlsx --union-projections '[["x", null], ["y", null]]'
    
    # ä½¿ç”¨å»é‡æŠ•å½±è‡ªå®šä¹‰èšåˆ
    python union-sheets.py data.xlsx --unique-projections '[["x", null], ["any_value(y)", "avg_y"]]'
    
    # åªåˆå¹¶ä¸å»é‡
    python union-sheets.py data.xlsx --no-dedupe
    
    # æŒ‡å®šè¾“å‡ºè¡¨åå’Œæ•°æ®åº“è·¯å¾„
    python union-sheets.py data.xlsx -o my_table -d my_data.db

å‘½ä»¤è¡Œå‚æ•°:
    excel_file                    Excelæ–‡ä»¶è·¯å¾„
    --union-projections, -up      UNIONé˜¶æ®µæŠ•å½±åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰
    --unique-projections, -uq     å»é‡é˜¶æ®µæŠ•å½±åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰
    --concurrent, -c             ä½¿ç”¨å¹¶å‘æ¨¡å¼å¤„ç†å¤šä¸ªsheets
    --max-workers, -w            å¹¶å‘æ¨¡å¼ä¸‹çš„æœ€å¤§çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰
    --no-dedupe                  åªåˆå¹¶ä¸å»é‡
    --output-table, -o           è¾“å‡ºè¡¨åï¼ˆé»˜è®¤: testï¼‰
    --db-path, -d                æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: excel.dbï¼‰

    --help, -h                   æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    
æµ‹è¯•ç¤ºä¾‹è¾“å‡º:
    [INFO] å‘ç° 2 ä¸ªsheet: ['Sheet1', 'Sheet2']
    [INFO] è¿æ¥åˆ°DuckDBæ•°æ®åº“: excel.db
    [INFO] ä½¿ç”¨ç¬¬ä¸€åˆ—è¿›è¡Œå»é‡: x
    [INFO] å»é‡å‰æ€»è¡Œæ•°: 6
    [INFO] å»é‡åè¡Œæ•°: 4
    [INFO] å»é‡æ“ä½œå®Œæˆï¼ŒæŒ‰ç¬¬ä¸€åˆ— 'x' å»é‡
    [INFO] å¤„ç†å®Œæˆï¼
"""

import argparse
import json
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Optional, Tuple

import duckdb
from openpyxl import load_workbook

# å¯¼å…¥ç»Ÿä¸€çš„æ—¥å¿—æ¨¡å—
from excel.log import (execute_sql_with_timing, log_error, log_info, log_success, log_warning, setup_logging)


# execute_sql_with_timing å‡½æ•°ç°åœ¨ä» log æ¨¡å—å¯¼å…¥


def get_sheet_names(excel_file: str) -> List[str]:
    """
    ä½¿ç”¨openpyxlè¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheetåç§°

    Args:
        excel_file: Excelæ–‡ä»¶è·¯å¾„

    Returns:
        sheetåç§°åˆ—è¡¨

    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        Exception: æ–‡ä»¶è¯»å–å¤±è´¥
    """
    if not os.path.exists(excel_file):
        raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")

    try:
        workbook = load_workbook(excel_file, read_only=True)
        sheet_names = workbook.sheetnames
        workbook.close()
        log_info(f"å‘ç° {len(sheet_names)} ä¸ªsheet: {sheet_names}")
        return sheet_names
    except Exception as e:
        raise Exception(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")


def union_sheets_concurrent(excel_file: str, table_name: str, conn: duckdb.DuckDBPyConnection,
                            projections: Optional[List[Tuple[str,
                            Optional[str]]]] = None,
                            max_workers: int = None) -> None:
    """
    Excelå¤šsheeté«˜æ•ˆå¹¶å‘åˆå¹¶å‡½æ•°

    Args:
        excel_file: Excelæ–‡ä»¶è·¯å¾„
        table_name: è¾“å‡ºè¡¨å
        conn: ä¸»DuckDBè¿æ¥å¯¹è±¡
        projections: æŠ•å½±åˆ—è¡¨
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°

    åŠŸèƒ½:
    - å¹¶å‘åˆ›å»ºä¸´æ—¶è¡¨ï¼Œä»»åŠ¡å®Œæˆåç«‹å³å†™å…¥åˆå¹¶è¡¨
    - ä»»ä¸€ä»»åŠ¡å¤±è´¥åˆ™å–æ¶ˆæ‰€æœ‰ä»»åŠ¡å¹¶æŠ›å‡ºå¼‚å¸¸
    - é«˜æ•ˆçš„æµå¼å¤„ç†ï¼Œé¿å…å†…å­˜ç§¯ç´¯
    """
    # è·å–sheetåç§°åˆ—è¡¨
    sheet_names = get_sheet_names(excel_file)
    if not sheet_names:
        log_warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•sheetï¼Œè·³è¿‡å¤„ç†")
        return

    if max_workers > len(sheet_names):
        max_workers = len(sheet_names)
    log_info(f"ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼Œæœ€å¤§çº¿ç¨‹æ•°: {max_workers}")

    # è½¬ä¹‰æ–‡ä»¶è·¯å¾„
    excel_file_escaped = excel_file.replace("\\", "\\\\")

    # æ„å»ºæŠ•å½±å­—ç¬¦ä¸²
    if projections is None:
        projection_str = "*"
        log_info("ä½¿ç”¨é»˜è®¤æŠ•å½±: SELECT *")
    else:
        projection_parts = []
        for expr, alias in projections:
            if alias and alias.strip():
                projection_parts.append(f"{expr} AS {alias}")
            else:
                projection_parts.append(expr)
        projection_str = ', '.join(projection_parts)
        log_info(f"ä½¿ç”¨è‡ªå®šä¹‰æŠ•å½±: SELECT {projection_str}")

    # é¢„å…ˆåŠ è½½Excelæ‰©å±•ï¼Œé¿å…å¹¶å‘å†²çª
    try:
        conn.execute("INSTALL excel")
        conn.execute("LOAD excel")
        log_success("Excelæ‰©å±•åŠ è½½æˆåŠŸ")
    except Exception as e:
        log_info(f"Excelæ‰©å±•å·²å­˜åœ¨æˆ–åŠ è½½å¤±è´¥: {e}")

    # è·å–ä¸»æ•°æ®åº“è·¯å¾„
    try:
        db_info = conn.execute("PRAGMA database_list").fetchone()
        db_path = db_info[2] if db_info and db_info[2] != '' else ":memory:"
    except:
        db_path = ":memory:"

    def process_sheet_task(sheet_info):
        """å¤„ç†å•ä¸ªsheetçš„ä»»åŠ¡"""
        sheet_index, sheet_name = sheet_info
        temp_table = f"temp_sheet_{sheet_index}_{int(time.time() * 1000) % 10000}"
        sheet_name_escaped = sheet_name.replace("'", "''")

        # åˆ›å»ºç‹¬ç«‹è¿æ¥
        thread_conn = duckdb.connect(db_path)

        try:
            # ç¡®ä¿Excelæ‰©å±•å·²åŠ è½½ï¼ˆé™é»˜å¤„ç†ï¼Œé¿å…å†²çªï¼‰
            try:
                thread_conn.execute("LOAD excel")
            except:
                pass  # æ‰©å±•å¯èƒ½å·²ç»åŠ è½½ï¼Œå¿½ç•¥é”™è¯¯

            # åˆ›å»ºä¸´æ—¶è¡¨
            create_sql = f"""
            CREATE TABLE {temp_table} AS
            SELECT {projection_str} FROM read_xlsx(
                '{excel_file_escaped}',
                sheet='{sheet_name_escaped}',
                all_varchar=true
            )
            """

            start_time = time.time()
            thread_conn.execute(create_sql)
            execution_time = time.time() - start_time

            # è·å–è¡Œæ•°
            result = thread_conn.execute(
                f"SELECT COUNT(*) FROM {temp_table}").fetchone()
            row_count = result[0] if result else 0

            return {
                'sheet_name': sheet_name,
                'sheet_index': sheet_index,
                'temp_table': temp_table,
                'row_count': row_count,
                'execution_time': execution_time
            }

        finally:
            thread_conn.close()

    # åˆ é™¤å·²å­˜åœ¨çš„è¡¨
    execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {table_name}",
                            f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„è¡¨: {table_name}")

    # å¹¶å‘å¤„ç†å¹¶å®æ—¶åˆå¹¶
    log_info(f"ğŸš€ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶å‘å¤„ç† {len(sheet_names)} ä¸ªsheets")

    completed_sheets = []
    temp_tables = []
    total_rows = 0
    first_table_created = False

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_sheet = {
            executor.submit(process_sheet_task, (i, sheet_name)): sheet_name
            for i, sheet_name in enumerate(sheet_names)
        }

        try:
            # å®æ—¶å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_sheet):
                result = future.result()
                completed_sheets.append(result)
                temp_tables.append(result['temp_table'])
                total_rows += result['row_count']

                log_info(f"âœ… {result['sheet_name']}: {result['row_count']} è¡Œ "
                         f"(è€—æ—¶: {result['execution_time']:.3f}s)")

                # ç¬¬ä¸€ä¸ªå®Œæˆçš„ä»»åŠ¡ï¼šåˆ›å»ºç›®æ ‡è¡¨
                if not first_table_created:
                    execute_sql_with_timing(
                        conn,
                        f"CREATE TABLE {table_name} AS SELECT * FROM {result['temp_table']}",
                        f"ğŸ”„ åˆ›å»ºç›®æ ‡è¡¨: {result['sheet_name']}"
                    )
                    first_table_created = True
                else:
                    # åç»­ä»»åŠ¡ï¼šæ’å…¥æ•°æ®
                    execute_sql_with_timing(
                        conn,
                        f"INSERT INTO {table_name} SELECT * FROM {result['temp_table']}",
                        f"ğŸ“Š æ’å…¥æ•°æ®: {result['sheet_name']}"
                    )

        except Exception as e:
            # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
            for f in future_to_sheet:
                if not f.done():
                    f.cancel()

            # æ¸…ç†å·²åˆ›å»ºçš„ä¸´æ—¶è¡¨
            for temp_table in temp_tables:
                try:
                    conn.execute(f"DROP TABLE IF EXISTS {temp_table}")
                except:
                    pass

            # æ¸…ç†ç›®æ ‡è¡¨
            if first_table_created:
                try:
                    conn.execute(f"DROP TABLE IF EXISTS {table_name}")
                except:
                    pass

            raise Exception(f"å¹¶å‘å¤„ç†å¤±è´¥: {str(e)}")

    # æ¸…ç†æ‰€æœ‰ä¸´æ—¶è¡¨
    for temp_table in temp_tables:
        try:
            execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {temp_table}",
                                    f"ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶è¡¨: {temp_table}")
        except Exception as e:
            log_warning(f"âš ï¸  æ¸…ç†ä¸´æ—¶è¡¨ {temp_table} å¤±è´¥: {e}")

    log_success(f"å¹¶å‘å¤„ç†å®Œæˆï¼Œæ€»è¡Œæ•°: {total_rows}")
    log_success(f"ç»“æœä¿å­˜åˆ°è¡¨: {table_name}")

    # æ˜¾ç¤ºè¡¨ç»“æ„ä¿¡æ¯
    start_time = time.time()
    schema_result = conn.execute(f"DESCRIBE {table_name}").fetchall()
    describe_time = time.time() - start_time
    log_info(f"ğŸ“‹ {table_name}è¡¨ç»“æ„ (æŸ¥è¯¢è€—æ—¶: {describe_time:.3f}s):")
    for column_info in schema_result:
        log_info(f"  {column_info[0]}: {column_info[1]}")


def union_sheets(excel_file: str, table_name: str, conn: duckdb.DuckDBPyConnection,
                 projections: Optional[List[Tuple[str, Optional[str]]]] = None) -> None:
    """
    Excelå¤šsheetåˆå¹¶å‡½æ•° - æ™ºèƒ½ä¼˜åŒ–çš„åˆå¹¶ç­–ç•¥

    Args:
        excel_file: Excelæ–‡ä»¶è·¯å¾„
        table_name: è¾“å‡ºè¡¨å
        conn: DuckDBè¿æ¥å¯¹è±¡
        projections: æŠ•å½±åˆ—è¡¨ï¼Œç”¨äºåœ¨UNIONé˜¶æ®µè¿‡æ»¤åˆ—ï¼Œæé«˜æ€§èƒ½
                    - None: é€‰æ‹©æ‰€æœ‰åˆ— (SELECT *)
                    - List: è‡ªå®šä¹‰æŠ•å½± [(è¡¨è¾¾å¼, åˆ«å), ...]

    åŠŸèƒ½:
    - è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰sheets
    - æ™ºèƒ½é€‰æ‹©åˆå¹¶ç­–ç•¥ï¼š
      * â‰¤3ä¸ªsheets: ä½¿ç”¨UNION ALLï¼ˆæ€§èƒ½æœ€ä½³ï¼‰
      * >3ä¸ªsheets: ä½¿ç”¨æ‰¹é‡INSERTï¼ˆé¿å…å·¨å¤§æŸ¥è¯¢ï¼‰
    - æ”¯æŒæŠ•å½±ä¼˜åŒ–ï¼Œå‡å°‘æ•°æ®ä¼ è¾“é‡

    Raises:
        Exception: æ“ä½œå¤±è´¥
    """
    # è·å–sheetåç§°åˆ—è¡¨
    sheet_names = get_sheet_names(excel_file)
    if not sheet_names:
        log_warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•sheetï¼Œè·³è¿‡å¤„ç†")
        return

    # è½¬ä¹‰æ–‡ä»¶è·¯å¾„ä¸­çš„åæ–œæ ï¼ˆWindowså…¼å®¹æ€§ï¼‰
    excel_file_escaped = excel_file.replace("\\", "\\\\")

    # æ„å»ºæŠ•å½±å­—ç¬¦ä¸²
    if projections is None:
        # æ²¡æœ‰æŠ•å½±ï¼Œé€‰æ‹©æ‰€æœ‰åˆ—
        projection_str = "*"
        log_info("ä½¿ç”¨é»˜è®¤æŠ•å½±: SELECT *")
    else:
        # ä½¿ç”¨è‡ªå®šä¹‰æŠ•å½±
        projection_parts = []
        for expr, alias in projections:
            if alias and alias.strip():
                projection_parts.append(f"{expr} AS {alias}")
            else:
                projection_parts.append(expr)
        projection_str = ', '.join(projection_parts)
        log_info(f"ä½¿ç”¨è‡ªå®šä¹‰æŠ•å½±: SELECT {projection_str}")

    # åˆ é™¤å·²å­˜åœ¨çš„è¡¨
    execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {table_name}",
                            f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„è¡¨: {table_name}")

    # ä¼˜åŒ–ç­–ç•¥ï¼šæ ¹æ®sheetæ•°é‡é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
    if len(sheet_names) > 3:
        # å¤šsheetä¼˜åŒ–ï¼šé€ä¸ªINSERTï¼Œé¿å…å·¨å¤§çš„UNION ALL
        log_info(f"ğŸš€ ä½¿ç”¨æ‰¹é‡INSERTæ¨¡å¼å¤„ç† {len(sheet_names)} ä¸ªsheetsï¼ˆä¼˜åŒ–å¤§æ•°æ®é‡ï¼‰")

        total_rows = 0
        for i, sheet_name in enumerate(sheet_names):
            sheet_name_escaped = sheet_name.replace("'", "''")

            if i == 0:
                # ç¬¬ä¸€ä¸ªsheetï¼šåˆ›å»ºè¡¨
                create_sql = f"""
                CREATE TABLE {table_name} AS
                SELECT {projection_str} FROM read_xlsx(
                    '{excel_file_escaped}',
                    sheet='{sheet_name_escaped}',
                    all_varchar=true
                )
                """
                execute_sql_with_timing(conn, create_sql,
                                        f"ğŸ“Š åˆ›å»ºè¡¨å¹¶æ’å…¥ç¬¬1ä¸ªsheet: {sheet_name}")
            else:
                # åç»­sheetï¼šæ‰¹é‡æ’å…¥
                insert_sql = f"""
                INSERT INTO {table_name}
                SELECT {projection_str} FROM read_xlsx(
                    '{excel_file_escaped}',
                    sheet='{sheet_name_escaped}',
                    all_varchar=true
                )
                """
                execute_sql_with_timing(conn, insert_sql,
                                        f"ğŸ“Š æ’å…¥ç¬¬{i + 1}ä¸ªsheet: {sheet_name}")

            # è·å–å½“å‰æ€»è¡Œæ•°
            result = conn.execute(
                f"SELECT COUNT(*) FROM {table_name}").fetchone()
            current_rows = result[0] if result else 0
            sheet_rows = current_rows - total_rows
            total_rows = current_rows
            log_info(
                f"  ğŸ“ˆ {sheet_name}: +{sheet_rows} è¡Œï¼Œç´¯è®¡: {total_rows} è¡Œ")

    else:
        # å°‘é‡sheetï¼šä½¿ç”¨ä¼ ç»ŸUNION ALLï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
        log_info(f"ğŸ”„ ä½¿ç”¨UNION ALLæ¨¡å¼å¤„ç† {len(sheet_names)} ä¸ªsheets")

        union_queries = []
        for sheet_name in sheet_names:
            sheet_name_escaped = sheet_name.replace("'", "''")
            query = (f"SELECT {projection_str} FROM read_xlsx("
                     f"'{excel_file_escaped}', sheet='{sheet_name_escaped}', "
                     f"all_varchar=true)")
            union_queries.append(query)
            log_info(f"  ğŸ“‹ æ·»åŠ sheet: {sheet_name}")

        # ç»„åˆæ‰€æœ‰æŸ¥è¯¢
        full_union_query = " UNION ALL ".join(union_queries)
        create_sql = f"CREATE TABLE {table_name} AS ({full_union_query})"

        execute_sql_with_timing(conn, create_sql, "ğŸ”„ æ‰§è¡ŒUNION ALLæ“ä½œ")

        # è·å–ç»“æœç»Ÿè®¡
        result = conn.execute(f"SELECT COUNT(*) FROM {table_name}").fetchone()
        total_rows = result[0] if result else 0

    log_info(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {total_rows}")
    log_info(f"âœ… ç»“æœä¿å­˜åˆ°è¡¨: {table_name}")

    # æ˜¾ç¤ºè¡¨ç»“æ„ä¿¡æ¯
    start_time = time.time()
    schema_result = conn.execute(f"DESCRIBE {table_name}").fetchall()
    describe_time = time.time() - start_time
    log_info(f"ğŸ“‹ {table_name}è¡¨ç»“æ„ (æŸ¥è¯¢è€—æ—¶: {describe_time:.3f}s):")
    for column_info in schema_result:
        log_info(f"  {column_info[0]}: {column_info[1]}")


def unique_keys(conn: duckdb.DuckDBPyConnection,
                table_name: str,
                projections: List[Tuple[str, Optional[str]]]) -> str:
    """
    æ•°æ®å»é‡å‡½æ•° - æŒ‰é”®å»é‡å¹¶æ”¯æŒè‡ªå®šä¹‰æŠ•å½±

    Args:
        conn: DuckDBè¿æ¥å¯¹è±¡
        table_name: è¾“å…¥è¡¨å
        projections: æŠ•å½±åˆ—è¡¨ [(è¡¨è¾¾å¼, åˆ«å), ...]
                    - ç¬¬ä¸€é¡¹å¿…é¡»æ˜¯keyåˆ—
                    - åˆ«åä¸ºNoneæˆ–ç©ºæ—¶ç›´æ¥ä½¿ç”¨è¡¨è¾¾å¼
                    - åˆ«åä¸ä¸ºç©ºæ—¶ä½¿ç”¨ expr AS alias

    Returns:
        æ–°è¡¨å: u_{table_name}

    åŠŸèƒ½:
    - ä½¿ç”¨GROUP BY ALLè‡ªåŠ¨å»é‡
    - æ”¯æŒçµæ´»çš„åˆ—æŠ•å½±å’Œé‡å‘½å

    Raises:
        Exception: æ“ä½œå¤±è´¥
    """
    if not projections:
        raise Exception("æŠ•å½±åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

    # ç”Ÿæˆæ–°è¡¨å
    new_table_name = f"u_{table_name}"

    # æ„å»ºæŠ•å½±å­—ç¬¦ä¸²
    projection_parts = []
    for expr, alias in projections:
        if alias and alias.strip():
            # æœ‰åˆ«åï¼Œä½¿ç”¨ expr AS alias
            projection_parts.append(f"{expr} AS {alias}")
        else:
            # æ²¡æœ‰åˆ«åï¼Œç›´æ¥ä½¿ç”¨expr
            projection_parts.append(expr)

    projection_str = ', '.join(projection_parts)

    # åˆ é™¤å·²å­˜åœ¨çš„æ–°è¡¨
    execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {new_table_name}",
                            f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„è¡¨: {new_table_name}")

    # ä½¿ç”¨GROUP BY ALLè¿›è¡Œå»é‡
    # GROUP BY ALLä¼šè‡ªåŠ¨æŒ‰æ‰€æœ‰éèšåˆåˆ—è¿›è¡Œåˆ†ç»„
    group_by_sql = f"""
    CREATE TABLE {new_table_name} AS
    SELECT {projection_str}
    FROM {table_name}
    GROUP BY ALL
    ORDER BY 1 ASC
    """

    log_info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå»é‡æ“ä½œ: {table_name} -> {new_table_name}")
    start_time = time.time()
    conn.execute(group_by_sql)
    group_by_time = time.time() - start_time
    log_info(f"â±ï¸  GROUP BYå»é‡æ‰§è¡Œå®Œæˆ (è€—æ—¶: {group_by_time:.3f}s)")

    # è·å–ç»“æœç»Ÿè®¡
    start_time = time.time()
    original_count = conn.execute(
        f"SELECT COUNT(*) FROM {table_name}").fetchone()[0]
    new_count = conn.execute(
        f"SELECT COUNT(*) FROM {new_table_name}").fetchone()[0]
    count_time = time.time() - start_time

    log_info(f"ğŸ“Š å»é‡å‰è¡Œæ•°: {original_count}")
    log_info(f"ğŸ“Š å»é‡åè¡Œæ•°: {new_count} (ç»Ÿè®¡è€—æ—¶: {count_time:.3f}s)")
    log_info(f"âœ… å»é‡å®Œæˆï¼Œç»“æœä¿å­˜åˆ°è¡¨: {new_table_name}")

    # æ˜¾ç¤ºæ–°è¡¨ç»“æ„ä¿¡æ¯
    start_time = time.time()
    schema_result = conn.execute(f"DESCRIBE {new_table_name}").fetchall()
    describe_time = time.time() - start_time
    log_info(f"ğŸ“‹ {new_table_name}è¡¨ç»“æ„ (æŸ¥è¯¢è€—æ—¶: {describe_time:.3f}s):")
    for column_info in schema_result:
        log_info(f"  {column_info[0]}: {column_info[1]}")

    return new_table_name


def parse_projections(proj_str: str) -> List[Tuple[str, Optional[str]]]:
    """
    è§£æå‘½ä»¤è¡ŒæŠ•å½±å‚æ•°

    Args:
        proj_str: æŠ•å½±å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºJSONæ•°ç»„
                 ä¾‹å¦‚: '[["x", null], ["any_value(y)", "y"], ["COUNT(*)", "count"]]'

    Returns:
        æŠ•å½±åˆ—è¡¨
    """
    try:
        proj_list = json.loads(proj_str)
        projections = []
        for item in proj_list:
            if isinstance(item, list) and len(item) == 2:
                expr, alias = item
                # å°†nullè½¬æ¢ä¸ºNone
                alias = None if alias is None or alias == "null" else alias
                projections.append((expr, alias))
            else:
                raise ValueError(f"æŠ•å½±é¡¹æ ¼å¼é”™è¯¯: {item}")
        return projections
    except json.JSONDecodeError as e:
        raise ValueError(f"æŠ•å½±å‚æ•°JSONæ ¼å¼é”™è¯¯: {e}")
    except Exception as e:
        raise ValueError(f"æŠ•å½±å‚æ•°è§£æå¤±è´¥: {e}")


def main():
    """
    ä¸»å‡½æ•°:
    - è§£æå‘½ä»¤è¡Œå‚æ•°
    - è¯»å–Excelæ–‡ä»¶çš„sheetåˆ—è¡¨
    - æ‰§è¡ŒUNIONå’Œå»é‡æ“ä½œ
    """
    parser = argparse.ArgumentParser(
        description='Excelå¤šsheetåˆå¹¶å’Œå»é‡å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼ˆæŒ‰ç¬¬ä¸€åˆ—è‡ªåŠ¨å»é‡ï¼‰
  python union-sheets.py data.xlsx
  
  # ä½¿ç”¨UNIONæŠ•å½±ä¼˜åŒ–æ€§èƒ½ï¼ˆåªé€‰æ‹©éœ€è¦çš„åˆ—ï¼‰
  python union-sheets.py data.xlsx --union-projections '[["x", null], ["y", null], ["z", null]]'
  
  # ä½¿ç”¨å»é‡æŠ•å½±è‡ªå®šä¹‰èšåˆ
  python union-sheets.py data.xlsx --unique-projections '[["x", null], ["any_value(y)", "avg_y"], ["COUNT(*)", "count"]]'
  
  # åŒæ—¶ä½¿ç”¨ä¸¤ç§æŠ•å½±
  python union-sheets.py data.xlsx -up '[["x", null], ["y", null]]' -uq '[["x", null], ["any_value(y)", "y"]]'
  
  # ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼ˆé€‚åˆå¤§é‡sheetsï¼‰
  python union-sheets.py data.xlsx --concurrent --max-workers 8
  
  # åªåˆå¹¶ä¸å»é‡
  python union-sheets.py data.xlsx --no-dedupe
  


æŠ•å½±æ ¼å¼è¯´æ˜:
  æŠ•å½±å‚æ•°ä¸ºJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ ä¸º[è¡¨è¾¾å¼, åˆ«å]çš„æ ¼å¼
  - è¡¨è¾¾å¼: SQLè¡¨è¾¾å¼ï¼Œå¦‚ "x", "any_value(y)", "COUNT(*)"
  - åˆ«å: åˆ—åˆ«åï¼Œå¯ä»¥ä¸ºnullï¼ˆä¸ä½¿ç”¨åˆ«åï¼‰æˆ–å­—ç¬¦ä¸²
  
  UNIONæŠ•å½± (--union-projections):
  - ç”¨äºåœ¨åˆå¹¶é˜¶æ®µè¿‡æ»¤åˆ—ï¼Œæé«˜æ€§èƒ½
  - å»ºè®®åªé€‰æ‹©éœ€è¦çš„åˆ—ï¼Œé¿å…ä¼ è¾“å¤§é‡æ— ç”¨æ•°æ®
  
  å»é‡æŠ•å½± (--unique-projections):
  - ç”¨äºå»é‡é˜¶æ®µçš„åˆ—é€‰æ‹©å’Œèšåˆ
  - ç¬¬ä¸€ä¸ªæŠ•å½±é¡¹å¿…é¡»æ˜¯keyåˆ—
  - å…¶ä»–åˆ—é€šå¸¸ä½¿ç”¨èšåˆå‡½æ•°å¦‚any_value()
        '''
    )

    parser.add_argument('excel_file', nargs='?', help='Excelæ–‡ä»¶è·¯å¾„')

    parser.add_argument('--union-projections', '-up', type=str,
                        help='UNIONé˜¶æ®µæŠ•å½±åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œç”¨äºæ€§èƒ½ä¼˜åŒ–ï¼Œä¾‹å¦‚: \'[["x", null], ["y", null]]\'')
    parser.add_argument('--unique-projections', '-uq', type=str,
                        help='å»é‡é˜¶æ®µæŠ•å½±åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œä¾‹å¦‚: \'[["x", null], ["any_value(y)", "y"]]\'')
    parser.add_argument('--concurrent', '-c', action='store_true',
                        help='ä½¿ç”¨å¹¶å‘æ¨¡å¼å¤„ç†å¤šä¸ªsheetsï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰')
    parser.add_argument('--max-workers', '-w', type=int, default=4,
                        help='å¹¶å‘æ¨¡å¼ä¸‹çš„æœ€å¤§çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--no-dedupe', action='store_true', help='åªåˆå¹¶ä¸å»é‡')
    parser.add_argument('--output-table', '-o',
                        default='test', help='è¾“å‡ºè¡¨åï¼ˆé»˜è®¤: testï¼‰')
    parser.add_argument('--db-path', '-d', default='excel.db',
                        help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: excel.dbï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥å¿…éœ€å‚æ•°
    if not args.excel_file:
        parser.error("è¯·æä¾›Excelæ–‡ä»¶è·¯å¾„")

    excel_file = args.excel_file

    try:
        # è®¾ç½®ç»Ÿä¸€çš„æ—¥å¿—é…ç½®
        setup_logging()

        # åˆ›å»ºDuckDBè¿æ¥
        conn = duckdb.connect(database=args.db_path)
        log_info(f"è¿æ¥åˆ°DuckDBæ•°æ®åº“: {args.db_path}")

        try:
            # è§£æUNIONæŠ•å½±
            union_projections = None
            if args.union_projections:
                union_projections = parse_projections(args.union_projections)
                log_info(f"ğŸ”§ UNIONé˜¶æ®µæŠ•å½±: {union_projections}")

            # æ­¥éª¤1: åˆå¹¶æ‰€æœ‰sheets
            temp_table = "temp_union_all"
            if args.concurrent:
                log_info(f"ğŸš€ ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼Œæœ€å¤§çº¿ç¨‹æ•°: {args.max_workers}")
                union_sheets_concurrent(
                    excel_file, temp_table, conn, union_projections, args.max_workers)
            else:
                union_sheets(excel_file, temp_table, conn, union_projections)

            if args.no_dedupe:
                # åªåˆå¹¶ä¸å»é‡ï¼Œç›´æ¥é‡å‘½å
                execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {args.output_table}",
                                        f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„è¡¨: {args.output_table}")
                execute_sql_with_timing(conn, f"ALTER TABLE {temp_table} RENAME TO {args.output_table}",
                                        f"ğŸ”„ é‡å‘½åè¡¨ä¸º: {args.output_table}")
                log_info(f"âœ… åˆå¹¶å®Œæˆï¼Œç»“æœä¿å­˜åˆ°è¡¨: {args.output_table}")
            else:
                # æ­¥éª¤2: å»é‡å¤„ç†
                unique_projections = None
                if args.unique_projections:
                    # ä½¿ç”¨è‡ªå®šä¹‰å»é‡æŠ•å½±
                    unique_projections = parse_projections(
                        args.unique_projections)
                    log_info(f"ğŸ”§ å»é‡é˜¶æ®µæŠ•å½±: {unique_projections}")
                else:
                    # ä½¿ç”¨é»˜è®¤æŠ•å½±ï¼ˆæŒ‰ç¬¬ä¸€åˆ—å»é‡ï¼‰
                    start_time = time.time()
                    columns_result = conn.execute(
                        f"DESCRIBE {temp_table}").fetchall()
                    describe_time = time.time() - start_time
                    log_info(f"â±ï¸  è·å–è¡¨ç»“æ„ä¿¡æ¯ (è€—æ—¶: {describe_time:.3f}s)")

                    if not columns_result:
                        raise Exception("æ— æ³•è·å–è¡¨ç»“æ„ä¿¡æ¯")

                    first_column = columns_result[0][0]
                    unique_projections = [(f'"{first_column}"', None)]  # keyåˆ—
                    for col_info in columns_result[1:]:
                        col_name = col_info[0]
                        unique_projections.append(
                            (f'any_value("{col_name}")', col_name))

                    log_info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤å»é‡æŠ•å½±ï¼ˆæŒ‰ç¬¬ä¸€åˆ— '{first_column}' å»é‡ï¼‰")

                # æ‰§è¡Œå»é‡
                result_table = unique_keys(
                    conn, temp_table, unique_projections)

                # é‡å‘½åä¸ºç›®æ ‡è¡¨
                execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {args.output_table}",
                                        f"ğŸ—‘ï¸  åˆ é™¤å·²å­˜åœ¨çš„è¡¨: {args.output_table}")
                execute_sql_with_timing(conn, f"ALTER TABLE {result_table} RENAME TO {args.output_table}",
                                        f"ğŸ”„ é‡å‘½åè¡¨ä¸º: {args.output_table}")

                # æ¸…ç†ä¸´æ—¶è¡¨
                execute_sql_with_timing(conn, f"DROP TABLE IF EXISTS {temp_table}",
                                        "ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶è¡¨")

                log_info(f"âœ… å»é‡å®Œæˆï¼Œç»“æœä¿å­˜åˆ°è¡¨: {args.output_table}")

        finally:
            conn.close()
            log_info("DuckDBè¿æ¥å·²å…³é—­")

        log_info("ğŸ‰ å¤„ç†å®Œæˆï¼")

    except Exception as e:
        log_error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
